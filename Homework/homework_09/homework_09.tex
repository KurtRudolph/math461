\documentclass{article}
\usepackage{hw_style}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{verbatim}
\usepackage{amsmath}
\usepackage{mathtools}

% Homework Specific Information
\newcommand{\hmwkTitle}{Homework \#9}
\newcommand{\hmwkDueDate}{Monday, July 16, 2012}
\newcommand{\hmwkAuthorName}{Kurt Rudolph}%Name:
\newcommand{\hmwkNetID}{rudolph9}%your netid
\newcommand{\hmwkNotes}{}%I worked with...

\newcommand{\hmwkSubTitle}{}
\newcommand{\hmwkClass}{Math 461}
\newcommand{\hmwkClassTime}{}
\newcommand{\hmwkClassInstructor}{Kenneth B. Stolarsky}

\begin{document}
\begin{spacing}{1.1}
\maketitle

%=============================p.228 #18==========================% 
\newpage
\begin{homeworkProblem}
  {\bf Chapter 5, Theoretical Exercise 18}\\
  Verify that the gamma density function integrates to 1.
  
  \begin{homeworkSection}{Definitions}
    A random variable is said to have a gamma distribution with parameters
    $(\alpha, \lambda), \lambda > 0, \alpha > 0$, if it's densit function
    is given by
    \[
      f( x) = \left\{
        \begin{array}{l l}
        \frac{ \lambda e^{-\lambda x} (\lambda x)^{\alpha - 1}}
             { \Gamma( \alpha)} &x \ge 0\\
        0 &x < 0 
        \end{array} \right.
    \]
    The quantity $\Gamma( \alpha)$ is call the \emph{gamma function}
    and is defined by
      \[\Gamma( \alpha) = \int\limits_0^\infty e^{-x} x^{\alpha - 1} dx\]
    and it follows that
      \[E[ X] = \frac{ \alpha}{ \lambda}\]
      \[Var(X) = \frac{ \alpha}{ \lambda^2}\]
  \end{homeworkSection}
  \begin{homeworkSection}{Solution}
    \begin{align*}
      \int\limits_0^\infty \frac{ \lambda e^{-\lambda x} (\lambda x)^{\alpha - 1}}
        { \Gamma( \alpha)} dx 
      &= \int\limits_0^\infty \frac{ 1}{ \Gamma( \alpha)}
        \lambda e^{-\lambda x} (\lambda x)^{\alpha - 1} dx\\
      &= \frac{ 1}{ \Gamma( \alpha)} \int\limits_0^\infty
        \lambda e^{-\lambda x} (\lambda x)^{\alpha - 1} dx\\
      \text{ Let $y = \lambda x$ where $dy = \lambda dx$}\\
      &= \frac{ 1}{ \Gamma( \alpha)} \int\limits_0^\infty
        e^{-y} (y)^{\alpha - 1} dy\\
      \text{Since $\Gamma( \alpha) = \int\limits_0^\infty e^{-y} y^{\alpha - 1} dy$}\\
      &= 1
    \end{align*}
  \end{homeworkSection}
\end{homeworkProblem}

%=============================p.228 #19==========================% 
\newpage
\begin{homeworkProblem}
  {\bf Chapter 5, Theoretical Exercise 19}\\
  If $X$ is an exponential random variable with mean $1/\lambda$, show that
  \[E[ X^k] = \frac{ k!}{ \lambda^k}, k = 1, 2, \dots\]
  \emph{Hint}: Make use of the gamma density function to evaluate the preceding.
  \begin{homeworkSection}{Definitions}
    {\bf Exponential Random Variable}\\
    A continuous random variable whose probability density 
    function is given, for some $\lambda > 0$, by
      \[
        f(x) = \left\{
          \begin{array}{l l}
            \lambda e^{-\lambda x} &if x \ge 0\\
            0 &if x < 0
          \end{array} \right.
      \]
    is said to be an \emph{exponential random variable} (or, more simply, 
    is said to be exponentially distributed) with parameter $\lambda$. 
    The cumulative distribution function $F( a)$ of an exponential 
    random variable is given by
      \begin{align*}
        F(a) &= P\{ X \le a \}\\
        &= \int\limits_0^a \lambda e^{-\lambda x} dx\\
        &= \left.-e^{-\lambda x}\right|_0^a\\
        &= 1 - e^{-\lambda a},  a \ge 0
      \end{align*}
    Where
      \begin{align*}
        E[ X] &= \frac{ 1}{ \lambda}\\
        Var( X) &= \frac{ 1}{ \lambda^2}
      \end{align*}
    \emph{Note}: $F(q) = \int\limits_0^\infty \lambda e^{-\lambda x} dx = 1$, 
    as, of course, it must.\\
    {\bf Gamma Distribution}\\
    A random variable is said to have a \emph{gamma distribution} with parameters
    $(\alpha, \lambda), \lambda > 0, \alpha > 0$, if it's densit function
    is given by
    \[
      f( x) = \left\{
        \begin{array}{l l}
        \frac{ \lambda e^{-\lambda x} (\lambda x)^{\alpha - 1}}
             { \Gamma( \alpha)} &x \ge 0\\
        0 &x < 0 
        \end{array} \right.
    \]
    The quantity $\Gamma( \alpha)$ is call the \emph{gamma function}
    and is defined by
      \[\Gamma( \alpha) = \int\limits_0^\infty e^{-x} x^{\alpha - 1} dx\]
    and it follows that
      \[E[ X] = \frac{ \alpha}{ \lambda}\]
      \[Var(X) = \frac{ \alpha}{ \lambda^2}\]\\
  \end{homeworkSection}
  \begin{homeworkSection}{Solution}
    \begin{align*}
      E[ X^k] &= \int\limits_0^\infty x^k \lambda e^{-\lambda x} dx\\
      \text{Let $v = \lambda x$ where $dv = \lambda d x$}\\
      &= \int\limits_0^\infty \lambda^{-k} v^k e^{-v} dv\\
      &= \frac{ 1}{ \lambda^k} \int\limits_0^\infty e^{-v} v^k dv\\
      \text{Since $\Gamma( \alpha) = \int\limits_0^\infty e^{-x} x^{\alpha -1} dx
      \Rightarrow \Gamma( \alpha + 1) = \int\limits_0^\infty e^{-x} x^{\alpha} dx$,}\\
      \text{and as shown in our text $\Gamma( n) = (n - 1)!$ where $n$ is an integer,}\\
      \text{hence $\Gamma( n + 1) = n!$, therefore}\\
      &= \frac{ k!}{ \lambda^k}
    \end{align*}
    
  \end{homeworkSection}
\end{homeworkProblem}

%=============================p.228 #20==========================% 
\newpage
\begin{homeworkProblem}
  {\bf Chapter 5, Theoretical Exercise 20}\\
  Verify that
  \[Var( X) = \frac{ \alpha}{ \lambda^2}\]
  when $X$ is a gamma random variable with parameters $\alpha$ and $\lambda$.
  \begin{homeworkSection}{Definitions}
    {\bf Gamma Distribution}\\
    A random variable is said to have a \emph{gamma distribution} with parameters
    $(\alpha, \lambda), \lambda > 0, \alpha > 0$, if it's densit function
    is given by
    \[
      f( x) = \left\{
        \begin{array}{l l}
        \frac{ \lambda e^{-\lambda x} (\lambda x)^{\alpha - 1}}
             { \Gamma( \alpha)} &x \ge 0\\
        0 &x < 0 
        \end{array} \right.
    \]
    The quantity $\Gamma( \alpha)$ is call the \emph{gamma function}
    and is defined by
      \[\Gamma( \alpha) = \int\limits_0^\infty e^{-x} x^{\alpha - 1} dx\]
    and it follows that
      \[E[ X] = \frac{ \alpha}{ \lambda}\]
      \[Var(X) = \frac{ \alpha}{ \lambda^2}\]\\
  \end{homeworkSection}
  \begin{homeworkSection}{Solution}
    \begin{align*}
      Var( X) &= E[ X^2] - (E[ X])^2\\
      &= \int\limits_0^\infty x^2 \frac{ \lambda e^{-\lambda x} (\lambda x)^{\alpha - 1}}
        {\Gamma( \alpha)} dx - \frac{ \alpha^2}{ \lambda^2}\\
      &= \frac{ 1}{ \Gamma( \alpha)} \int\limits_0^\infty x^2
        \lambda e^{-\lambda x} (\lambda x)^{\alpha - 1} dx - \frac{ \alpha^2}{ \lambda^2}\\
      &= \frac{ 1}{ \Gamma( \alpha)} \int\limits_0^\infty
        e^{-\lambda x} \lambda^\alpha x^{\alpha + 1} dx - \frac{ \alpha^2}{ \lambda^2}\\
      \text{Let $v = \lambda x$ where $dv = \lambda d x$}\\
      &= \frac{ 1}{ \Gamma( \alpha)} \int\limits_0^\infty
        e^{-v} \frac{ v^{\alpha + 1}}{ \lambda} \frac{dv}{ \lambda} - \frac{ \alpha^2}{ \lambda^2}\\
      &= \frac{ 1}{ \Gamma( \alpha) \lambda^2} \int\limits_0^\infty
        e^{-v} v^{\alpha + 1} dv - \frac{ \alpha^2}{ \lambda^2}\\
      &= \frac{ \Gamma( \alpha + 2)}{ \Gamma( \alpha) \lambda^2} - \frac{ \alpha^2}{ \lambda^2}\\
      &= \frac{ (\alpha + 1)\Gamma( \alpha + 1)}{ \Gamma( \alpha) \lambda^2} - \frac{ \alpha^2}{ \lambda^2}\\
      &= \frac{ (\alpha + 1)(\alpha)\Gamma( \alpha)}{ \Gamma( \alpha) \lambda^2} - \frac{ \alpha^2}{ \lambda^2}\\
      &= \frac{ (\alpha + 1)(\alpha)}{ \lambda^2} - \frac{ \alpha^2}{ \lambda^2}\\
      &= \frac{ \alpha^2 + \alpha}{ \lambda^2} - \frac{ \alpha^2}{ \lambda^2}\\
      &= \frac{\alpha}{ \lambda^2}\\
    \end{align*}
  \end{homeworkSection}
\end{homeworkProblem}

%=============================p.228 #21==========================% 
\newpage
\begin{homeworkProblem}
  {\bf Chapter 5, Theoretical Exercise 21}\\
  Show that 
  \[\Gamma \left(\frac{ 1}{ 2}\right) = \sqrt{ \pi}\]
  \emph{Hint}: $\Gamma\left( \frac{ 1}{ 2}\right) = \int\limits_0^{\infty} e^{-x} x^{-1/2} dx$. 
  Make the change of variables $y = \sqrt{ 2x}$ and then relate the resulting expression
  to the normal distribution.
  \begin{homeworkSection}{Solution}
    \begin{align*}
      \Gamma\left( \frac{ 1}{ 2}\right) &= \int\limits_0^{\infty} e^{-x} x^{-1/2} dx\\
      \text{Let $y =  (2x)^{1/2}$ where $dy = (2x)^{-1/2} dx$}\\
      &= \int\limits_0^{\infty} e^{-y^2/2} 2^{-1/2} dy\\
      &= 2^{-1/2} \int\limits_0^{\infty} e^{-y^2/2} dy\\
      \text{As shown in the text in section 5.4 
        $\int\limits_0^{\infty} e^{-y^2/2} dy = \sqrt{2 \pi}$}\\
      &= \frac{ \sqrt{ 2 \pi}}{ \sqrt{ 2}} = \sqrt{ \pi}
    \end{align*}
  \end{homeworkSection}
\end{homeworkProblem}

%=============================p.228 #26==========================% 
\newpage
\begin{homeworkProblem}
  {\bf Chapter 5, Theoretical Exercise 26}\\
  If $X$ is a beta random variable with parameters $a$ and $b$  
  \begin{homeworkSection}{Definitions}
    {\bf Beta Distribution}\\
      \[
        f( x) = 
        \left\{ \begin{array}{l l}
          \frac{ 1}{ B(a, b)} x^{a - 1} (1 - x)^{b - 1} &0 < x < 1\\
          0 & \text{otherwise}
        \end{array} \right.
      \]
      where
      \begin{align*}
        B(a, b) &= \int\limits_0^1 x^{a -1} (1 - x)^{b - 1} d x\\
        E[ X] &= \frac{ a}{ a + b}\\
        Var( X) &= \frac{ ab}{ (a + b)^2 (a + b + 1)}\\
      \end{align*}
    {\bf Equation (6.3)}\\
        \[B( a, b) = \frac{ \Gamma( a) \Gamma( b)}{ \Gamma( a + b)}\]
  \end{homeworkSection}
  Using equation (6.3) and $\Gamma( n + 1) = n \Gamma( n)$.
  \begin{enumerate}[(a)]
    \item Show $E[ X] = \frac{ a}{ a + b}$
      \begin{homeworkSection}{Solution}
        \begin{align*}
          E[X] &= \int\limits_0^1 x \frac{ 1}{ B(a, b)} x^{a - 1} (1 - x)^{b - 1} dx\\
          &= \int\limits_0^1 \frac{ 1}{ B(a, b)} x^{a} (1 - x)^{b - 1} dx\\
          &= \int\limits_0^1 \frac{ 1}{ \frac{ \Gamma( a) \Gamma( b)}{ \Gamma( a + b)}} 
              x^{a} (1 - x)^{b - 1} dx\\
          &= \int\limits_0^1 \frac{ \Gamma( a + b)}{ \Gamma( a) \Gamma( b)} 
              x^{a} (1 - x)^{b - 1} dx\\
          &= \frac{\Gamma( a + b)}{ \Gamma( a) \Gamma( b)} \int\limits_0^1
              x^{a} (1 - x)^{b - 1} dx\\
          &= \frac{ \Gamma( a + b)}{ \Gamma( a) \Gamma( b)} B(a + 1, b)\\
          &= \frac{ \Gamma( a + b)}{ \Gamma( a) \Gamma( b)} 
            \frac{ \Gamma( a + 1) \Gamma( b)}{ \Gamma( a + 1 + b)} \\
          &= \frac{ \Gamma( a + b)}{ \Gamma( a)} 
            \frac{ \Gamma( a + 1)}{ \Gamma( a + 1 + b)} \\
          &= \frac{ \Gamma( a + b)}{ \Gamma( a)} 
            \frac{ a\Gamma( a)}{ (a + b)\Gamma( a + b)} \\
          &= \frac{ a}{ (a + b)} \\
        \end{align*}
      \end{homeworkSection}
    \item Show $Var( X) = \frac{ ab}{ (a + b)^2 (a + b + 1)}$
      \begin{homeworkSection}{Solution}
        \begin{align*}
          Var( X) &= E[ X^2] - (E[ X])^2\\
          &= \int\limits_0^1 x^2 \frac{ 1}{ B(a, b)} x^{a - 1} (1 - x)^{b - 1} dx 
            - \frac{ a^2}{ (a + b)^2}\\
          &= \int\limits_0^1 \frac{ 1}{ B(a, b)} x^{a + 1} (1 - x)^{b - 1} dx 
            - \frac{ a^2}{ (a + b)^2}\\
          &= \frac{ \Gamma( a + b)}{ \Gamma( a) \Gamma( b)} B(a + 2, b)
            - \frac{ a^2}{ (a + b)^2}\\
          &= \frac{ \Gamma( a + b)}{ \Gamma( a)}
            \frac{ \Gamma( a + 2) \Gamma( b)}{ \Gamma( a + 2 + b)}
            - \frac{ a^2}{ (a + b)^2}\\
          &= \frac{ \Gamma( a + b)}{ \Gamma( a) }
            \frac{ (a + 1) (a) \Gamma( a) \Gamma( b)}{ ( a + 1 + b)( a + b)\Gamma( a + b)}
            - \frac{ a^2}{ (a + b)^2}\\
          &= \frac{ (a + 1) (a)}{ ( a + 1 + b)( a + b)}
            - \frac{ a^2}{ (a + b)^2}\\
          &= \frac{ (a + 1) (a) (a + b) - ( a + 1 + b) (a^2)}{ ( a + 1 + b) ( a + b)^2}\\
          &= \frac{ (a^2 + a) (a + b) - ( a^3 + a^2 + a^2 b)}{ ( a + 1 + b) ( a + b)^2}\\
          &= \frac{ (a^3 + a^2 b + a^2 + a b) - ( a^3 + a^2 + a^2 b)}{ ( a + 1 + b) ( a + b)^2}\\
          &= \frac{ a b}{ ( a + 1 + b) ( a + b)^2}\\
        \end{align*}
      \end{homeworkSection}
  \end{enumerate}
\end{homeworkProblem}

%=============================p.287 #9==========================% 
\newpage
\begin{homeworkProblem}
  {\bf Chapter 6, Exercise 9}\\
  The joint probability density function of $X$ and $Y$ is given by
  \[f( x, y) = \frac{ 6}{ 7} \left( x^2 + \frac{ x y}{ 2}\right), 
    0 < x < 1, 0 < y < 2\]

  \begin{homeworkSection}{Definitions}

  \end{homeworkSection}
  \begin{enumerate}[(a)]
    \item Verify that this is indeed a joint density function.
      \begin{homeworkSection}{Solution}

      \end{homeworkSection}
    \item Compute the density function of $X$.
      \begin{homeworkSection}{Solution}

      \end{homeworkSection}
    \item Find $P\{ X > Y\}$.
      \begin{homeworkSection}{Solution}

      \end{homeworkSection}
    \item Find $P\{ Y > \frac{ 1}{ 2}| X < \frac{ 1}{ 2}\}$.
      \begin{homeworkSection}{Solution}

      \end{homeworkSection}
    \item Find $E[ X]$
      \begin{homeworkSection}{Solution}

      \end{homeworkSection}
    \item Find $E[ Y]$
      \begin{homeworkSection}{Solution}

      \end{homeworkSection}
  \end{enumerate}
\end{homeworkProblem}

%=============================p.287 #10==========================% 
\newpage
\begin{homeworkProblem}
  {\bf Chapter 6, Exercise 10}\\
  The joint probability density function of $X$ and $Y$ is given by
    \[f( x, y) = e^{-(x + y)}, 0 \le x < \infty, 0 \le y < \infty\]
  Find 
  \begin{enumerate}[(a)]
    \item $P\{ X < Y\}$
      \begin{homeworkSection}{Solution}
        
      \end{homeworkSection}
    \item $P\{ X < a\}$
      \begin{homeworkSection}{Solution}
        
      \end{homeworkSection}
  \end{enumerate}
\end{homeworkProblem}

%=============================p.288 #22==========================% 
\newpage
\begin{homeworkProblem}
  {\bf Chapter 6, Exercise 23}\\
  The random variables $X$ and $Y$ have joint density function
  \[f( x, y) = 12 x y (1 - x), 0 < x < 1, 0 < y < 1\]
  and equal to 0 otherwise.
  \begin{enumerate}[(a)]
    \item Are $X$ and $Y$ independent?
      \begin{homeworkSection}{Solution}
        
      \end{homeworkSection}
    \item Find $E[ X]$
      \begin{homeworkSection}{Solution}
        
      \end{homeworkSection}
    \item Find $E[ Y]$
      \begin{homeworkSection}{Solution}
        
      \end{homeworkSection}
    \item Find $Var( X)$
      \begin{homeworkSection}{Solution}
        
      \end{homeworkSection}
    \item Find $Var( Y)$
      \begin{homeworkSection}{Solution}
        
      \end{homeworkSection}
  \end{enumerate}
\end{homeworkProblem}

%=============================p.289 #30==========================% 
\newpage
\begin{homeworkProblem}
  {\bf Chapter 6, Exercise 30}\\
  Jill's bowling scores are approximately normally distributed with 
  mean 170 and standard deviation 20, while Jack's scores are 
  approximately normally distributed with mean 160 and standard 
  deviation 15. If Jack and Jill each bowl one game, then assuming 
  that their scores are independent random variables, approximate 
  the probability that
  \begin{enumerate}[(a)]
    \item Jack's score is higher
      \begin{homeworkSection}{Solution}
        
      \end{homeworkSection}
    \item The total of their scores is above 350
      \begin{homeworkSection}{Solution}
        
      \end{homeworkSection}
  \end{enumerate}
\end{homeworkProblem}

\end{spacing}
\end{document}

\begin{comment}%==========================================================
* p.228
  * 18
  * 19
  * 20
  * 21
  * 26
      * Use p.218(6.3)  and \[\Gamma( n + 1) = n \Gamma( n)\]
* p.287
  * 9
  * 10
  * 23
  * 28
      * exp. significant
  * 30 
      * exp. significant
%=============================Problemi==========================% 
\newpage
\begin{homeworkProblem}
  
  \begin{homeworkSection}{Solution}
    
  \end{homeworkSection}
\end{homeworkProblem}
%=============================Problemi==========================% 
\newpage
\begin{homeworkProblem}
  
  \begin{enumerate}[(a)]
    \item 
      \begin{homeworkSection}{Solution}
    
      \end{homeworkSection}
  \end{enumerate}
\end{homeworkProblem}
