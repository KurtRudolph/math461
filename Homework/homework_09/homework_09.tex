\documentclass{article}
\usepackage{hw_style}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{verbatim}
\usepackage{amsmath}
\usepackage{mathtools}

% Homework Specific Information
\newcommand{\hmwkTitle}{Homework \#9}
\newcommand{\hmwkDueDate}{Monday, July 16, 2012}
\newcommand{\hmwkAuthorName}{Kurt Rudolph}%Name:
\newcommand{\hmwkNetID}{rudolph9}%your netid
\newcommand{\hmwkNotes}{}%I worked with...

\newcommand{\hmwkSubTitle}{}
\newcommand{\hmwkClass}{Math 461}
\newcommand{\hmwkClassTime}{}
\newcommand{\hmwkClassInstructor}{Kenneth B. Stolarsky}

\begin{document}
\begin{spacing}{1.1}
\maketitle

%=============================p.228 #18==========================% 
\newpage
\begin{homeworkProblem}
  {\bf Chapter 5, Theoretical Exercise 18}\\
  Verify that the gamma density function integrates to 1.
  
  \begin{homeworkSection}{Definitions}
    A random variable is said to have a gamma distribution with parameters
    $(\alpha, \lambda), \lambda > 0, \alpha > 0$, if it's densit function
    is given by
    \[
      f( x) = \left\{
        \begin{array}{l l}
        \frac{ \lambda e^{-\lambda x} (\lambda x)^{\alpha - 1}}
             { \Gamma( \alpha)} &x \ge 0\\
        0 &x < 0 
        \end{array} \right.
    \]
    The quantity $\Gamma( \alpha)$ is call the \emph{gamma function}
    and is defined by
      \[\Gamma( \alpha) = \int\limits_0^\infty e^{-x} x^{\alpha - 1} dx\]
    and it follows that
      \[E[ X] = \frac{ \alpha}{ \lambda}\]
      \[Var(X) = \frac{ \alpha}{ \lambda^2}\]
  \end{homeworkSection}
  \begin{homeworkSection}{Solution}
    \begin{align*}
      \int\limits_0^\infty \frac{ \lambda e^{-\lambda x} (\lambda x)^{\alpha - 1}}
        { \Gamma( \alpha)} dx 
      &= \int\limits_0^\infty \frac{ 1}{ \Gamma( \alpha)}
        \lambda e^{-\lambda x} (\lambda x)^{\alpha - 1} dx\\
      &= \frac{ 1}{ \Gamma( \alpha)} \int\limits_0^\infty
        \lambda e^{-\lambda x} (\lambda x)^{\alpha - 1} dx\\
      \text{ Let $y = \lambda x$ where $dy = \lambda dx$}\\
      &= \frac{ 1}{ \Gamma( \alpha)} \int\limits_0^\infty
        e^{-y} (y)^{\alpha - 1} dy\\
      \text{Since $\Gamma( \alpha) = \int\limits_0^\infty e^{-y} y^{\alpha - 1} dy$}\\
      &= 1
    \end{align*}
  \end{homeworkSection}
\end{homeworkProblem}

%=============================p.228 #19==========================% 
\newpage
\begin{homeworkProblem}
  {\bf Chapter 5, Theoretical Exercise 19}\\
  If $X$ is an exponential random variable with mean $1/\lambda$, show that
  \[E[ X^k] = \frac{ k!}{ \lambda^k}, k = 1, 2, \dots\]
  \emph{Hint}: Make use of the gamma density function to evaluate the preceding.
  \begin{homeworkSection}{Definitions}
    {\bf Exponential Random Variable}\\
    A continuous random variable whose probability density 
    function is given, for some $\lambda > 0$, by
      \[
        f(x) = \left\{
          \begin{array}{l l}
            \lambda e^{-\lambda x} &if x \ge 0\\
            0 &if x < 0
          \end{array} \right.
      \]
    is said to be an \emph{exponential random variable} (or, more simply, 
    is said to be exponentially distributed) with parameter $\lambda$. 
    The cumulative distribution function $F( a)$ of an exponential 
    random variable is given by
      \begin{align*}
        F(a) &= P\{ X \le a \}\\
        &= \int\limits_0^a \lambda e^{-\lambda x} dx\\
        &= \left.-e^{-\lambda x}\right|_0^a\\
        &= 1 - e^{-\lambda a},  a \ge 0
      \end{align*}
    Where
      \begin{align*}
        E[ X] &= \frac{ 1}{ \lambda}\\
        Var( X) &= \frac{ 1}{ \lambda^2}
      \end{align*}
    \emph{Note}: $F(q) = \int\limits_0^\infty \lambda e^{-\lambda x} dx = 1$, 
    as, of course, it must.\\
    {\bf Gamma Distribution}\\
    A random variable is said to have a \emph{gamma distribution} with parameters
    $(\alpha, \lambda), \lambda > 0, \alpha > 0$, if it's densit function
    is given by
    \[
      f( x) = \left\{
        \begin{array}{l l}
        \frac{ \lambda e^{-\lambda x} (\lambda x)^{\alpha - 1}}
             { \Gamma( \alpha)} &x \ge 0\\
        0 &x < 0 
        \end{array} \right.
    \]
    The quantity $\Gamma( \alpha)$ is call the \emph{gamma function}
    and is defined by
      \[\Gamma( \alpha) = \int\limits_0^\infty e^{-x} x^{\alpha - 1} dx\]
    and it follows that
      \[E[ X] = \frac{ \alpha}{ \lambda}\]
      \[Var(X) = \frac{ \alpha}{ \lambda^2}\]\\
  \end{homeworkSection}
  \begin{homeworkSection}{Solution}
    \begin{align*}
      E[ X^k] &= \int\limits_0^\infty x^k \lambda e^{-\lambda x} dx\\
      \text{Let $v = \lambda x$ where $dv = \lambda d x$}\\
      &= \int\limits_0^\infty \lambda^{-k} v^k e^{-v} dv\\
      &= \frac{ 1}{ \lambda^k} \int\limits_0^\infty e^{-v} v^k dv\\
      \text{Since $\Gamma( \alpha) = \int\limits_0^\infty e^{-x} x^{\alpha -1} dx
      \Rightarrow \Gamma( \alpha + 1) = \int\limits_0^\infty e^{-x} x^{\alpha} dx$,}\\
      \text{and as shown in our text $\Gamma( n) = (n - 1)!$ where $n$ is an integer,}\\
      \text{hence $\Gamma( n + 1) = n!$, therefore}\\
      &= \frac{ k!}{ \lambda^k}
    \end{align*}
    
  \end{homeworkSection}
\end{homeworkProblem}

%=============================p.228 #20==========================% 
\newpage
\begin{homeworkProblem}
  {\bf Chapter 5, Theoretical Exercise 20}\\
  Verify that
  \[Var( X) = \frac{ \alpha}{ \lambda^2}\]
  when $X$ is a gamma random variable with parameters $\alpha$ and $\lambda$.
  \begin{homeworkSection}{Definitions}
    {\bf Gamma Distribution}\\
    A random variable is said to have a \emph{gamma distribution} with parameters
    $(\alpha, \lambda), \lambda > 0, \alpha > 0$, if it's densit function
    is given by
    \[
      f( x) = \left\{
        \begin{array}{l l}
        \frac{ \lambda e^{-\lambda x} (\lambda x)^{\alpha - 1}}
             { \Gamma( \alpha)} &x \ge 0\\
        0 &x < 0 
        \end{array} \right.
    \]
    The quantity $\Gamma( \alpha)$ is call the \emph{gamma function}
    and is defined by
      \[\Gamma( \alpha) = \int\limits_0^\infty e^{-x} x^{\alpha - 1} dx\]
    and it follows that
      \[E[ X] = \frac{ \alpha}{ \lambda}\]
      \[Var(X) = \frac{ \alpha}{ \lambda^2}\]\\
  \end{homeworkSection}
  \begin{homeworkSection}{Solution}
    \begin{align*}
      Var( X) &= E[ X^2] - (E[ X])^2\\
      &= \int\limits_0^\infty x^2 \frac{ \lambda e^{-\lambda x} (\lambda x)^{\alpha - 1}}
        {\Gamma( \alpha)} dx - \frac{ \alpha^2}{ \lambda^2}\\
      &= \frac{ 1}{ \Gamma( \alpha)} \int\limits_0^\infty x^2
        \lambda e^{-\lambda x} (\lambda x)^{\alpha - 1} dx - \frac{ \alpha^2}{ \lambda^2}\\
      &= \frac{ 1}{ \Gamma( \alpha)} \int\limits_0^\infty
        e^{-\lambda x} \lambda^\alpha x^{\alpha + 1} dx - \frac{ \alpha^2}{ \lambda^2}\\
      \text{Let $v = \lambda x$ where $dv = \lambda d x$}\\
      &= \frac{ 1}{ \Gamma( \alpha)} \int\limits_0^\infty
        e^{-v} \frac{ v^{\alpha + 1}}{ \lambda} \frac{dv}{ \lambda} - \frac{ \alpha^2}{ \lambda^2}\\
      &= \frac{ 1}{ \Gamma( \alpha) \lambda^2} \int\limits_0^\infty
        e^{-v} v^{\alpha + 1} dv - \frac{ \alpha^2}{ \lambda^2}\\
      &= \frac{ \Gamma( \alpha + 2)}{ \Gamma( \alpha) \lambda^2} - \frac{ \alpha^2}{ \lambda^2}\\
      &= \frac{ (\alpha + 1)\Gamma( \alpha + 1)}{ \Gamma( \alpha) \lambda^2} - \frac{ \alpha^2}{ \lambda^2}\\
      &= \frac{ (\alpha + 1)(\alpha)\Gamma( \alpha)}{ \Gamma( \alpha) \lambda^2} - \frac{ \alpha^2}{ \lambda^2}\\
      &= \frac{ (\alpha + 1)(\alpha)}{ \lambda^2} - \frac{ \alpha^2}{ \lambda^2}\\
      &= \frac{ \alpha^2 + \alpha}{ \lambda^2} - \frac{ \alpha^2}{ \lambda^2}\\
      &= \frac{\alpha}{ \lambda^2}\\
    \end{align*}
  \end{homeworkSection}
\end{homeworkProblem}

%=============================p.228 #21==========================% 
\newpage
\begin{homeworkProblem}
  {\bf Chapter 5, Theoretical Exercise 21}\\
  Show that 
  \[\Gamma \left(\frac{ 1}{ 2}\right) = \sqrt{ \pi}\]
  \emph{Hint}: $\Gamma\left( \frac{ 1}{ 2}\right) = \int\limits_0^{\infty} e^{-x} x^{-1/2} dx$. 
  Make the change of variables $y = \sqrt{ 2x}$ and then relate the resulting expression
  to the normal distribution.
  \begin{homeworkSection}{Solution}
    \begin{align*}
      \Gamma\left( \frac{ 1}{ 2}\right) &= \int\limits_0^{\infty} e^{-x} x^{-1/2} dx\\
      \text{Let $y =  (2x)^{1/2}$ where $dy = (2x)^{-1/2} dx$}\\
      &= \int\limits_0^{\infty} e^{-y^2/2} 2^{-1/2} dy\\
      &= 2^{-1/2} \int\limits_0^{\infty} e^{-y^2/2} dy\\
      \text{As shown in the text in section 5.4 
        $\int\limits_0^{\infty} e^{-y^2/2} dy = \sqrt{2 \pi}$}\\
      &= \frac{ \sqrt{ 2 \pi}}{ \sqrt{ 2}} = \sqrt{ \pi}
    \end{align*}
  \end{homeworkSection}
\end{homeworkProblem}

%=============================p.228 #26==========================% 
\newpage
\begin{homeworkProblem}
  {\bf Chapter 5, Theoretical Exercise 26}\\
  If $X$ is a beta random variable with parameters $a$ and $b$  
  \begin{homeworkSection}{Definitions}
    {\bf Beta Distribution}\\
      \[
        f( x) = 
        \left\{ \begin{array}{l l}
          \frac{ 1}{ B(a, b)} x^{a - 1} (1 - x)^{b - 1} &0 < x < 1\\
          0 & \text{otherwise}
        \end{array} \right.
      \]
      where
      \begin{align*}
        B(a, b) &= \int\limits_0^1 x^{a -1} (1 - x)^{b - 1} d x\\
        E[ X] &= \frac{ a}{ a + b}\\
        Var( X) &= \frac{ ab}{ (a + b)^2 (a + b + 1)}\\
      \end{align*}
    {\bf Equation (6.3)}\\
        \[B( a, b) = \frac{ \Gamma( a) \Gamma( b)}{ \Gamma( a + b)}\]
  \end{homeworkSection}
  Using equation (6.3) and $\Gamma( n + 1) = n \Gamma( n)$.
  \begin{enumerate}[(a)]
    \item Show $E[ X] = \frac{ a}{ a + b}$
      \begin{homeworkSection}{Solution}
        \begin{align*}
          E[X] &= \int\limits_0^1 x \frac{ 1}{ B(a, b)} x^{a - 1} (1 - x)^{b - 1} dx\\
          &= \int\limits_0^1 \frac{ 1}{ B(a, b)} x^{a} (1 - x)^{b - 1} dx\\
          &= \int\limits_0^1 \frac{ 1}{ \frac{ \Gamma( a) \Gamma( b)}{ \Gamma( a + b)}} 
              x^{a} (1 - x)^{b - 1} dx\\
          &= \int\limits_0^1 \frac{ \Gamma( a + b)}{ \Gamma( a) \Gamma( b)} 
              x^{a} (1 - x)^{b - 1} dx\\
          &= \frac{\Gamma( a + b)}{ \Gamma( a) \Gamma( b)} \int\limits_0^1
              x^{a} (1 - x)^{b - 1} dx\\
          &= \frac{ \Gamma( a + b)}{ \Gamma( a) \Gamma( b)} B(a + 1, b)\\
          &= \frac{ \Gamma( a + b)}{ \Gamma( a) \Gamma( b)} 
            \frac{ \Gamma( a + 1) \Gamma( b)}{ \Gamma( a + 1 + b)} \\
          &= \frac{ \Gamma( a + b)}{ \Gamma( a)} 
            \frac{ \Gamma( a + 1)}{ \Gamma( a + 1 + b)} \\
          &= \frac{ \Gamma( a + b)}{ \Gamma( a)} 
            \frac{ a\Gamma( a)}{ (a + b)\Gamma( a + b)} \\
          &= \frac{ a}{ (a + b)} \\
        \end{align*}
      \end{homeworkSection}
    \item Show $Var( X) = \frac{ ab}{ (a + b)^2 (a + b + 1)}$
      \begin{homeworkSection}{Solution}
        \begin{align*}
          Var( X) &= E[ X^2] - (E[ X])^2\\
          &= \int\limits_0^1 x^2 \frac{ 1}{ B(a, b)} x^{a - 1} (1 - x)^{b - 1} dx 
            - \frac{ a^2}{ (a + b)^2}\\
          &= \int\limits_0^1 \frac{ 1}{ B(a, b)} x^{a + 1} (1 - x)^{b - 1} dx 
            - \frac{ a^2}{ (a + b)^2}\\
          &= \frac{ \Gamma( a + b)}{ \Gamma( a) \Gamma( b)} B(a + 2, b)
            - \frac{ a^2}{ (a + b)^2}\\
          &= \frac{ \Gamma( a + b)}{ \Gamma( a)}
            \frac{ \Gamma( a + 2) \Gamma( b)}{ \Gamma( a + 2 + b)}
            - \frac{ a^2}{ (a + b)^2}\\
          &= \frac{ \Gamma( a + b)}{ \Gamma( a) }
            \frac{ (a + 1) (a) \Gamma( a) \Gamma( b)}{ ( a + 1 + b)( a + b)\Gamma( a + b)}
            - \frac{ a^2}{ (a + b)^2}\\
          &= \frac{ (a + 1) (a)}{ ( a + 1 + b)( a + b)}
            - \frac{ a^2}{ (a + b)^2}\\
          &= \frac{ (a + 1) (a) (a + b) - ( a + 1 + b) (a^2)}{ ( a + 1 + b) ( a + b)^2}\\
          &= \frac{ (a^2 + a) (a + b) - ( a^3 + a^2 + a^2 b)}{ ( a + 1 + b) ( a + b)^2}\\
          &= \frac{ (a^3 + a^2 b + a^2 + a b) - ( a^3 + a^2 + a^2 b)}{ ( a + 1 + b) ( a + b)^2}\\
          &= \frac{ a b}{ ( a + 1 + b) ( a + b)^2}\\
        \end{align*}
      \end{homeworkSection}
  \end{enumerate}
\end{homeworkProblem}

%=============================p.287 #9==========================% 
\newpage
\begin{homeworkProblem}
  {\bf Chapter 6, Exercise 9}\\
  The joint probability density function of $X$ and $Y$ is given by
  \[f( x, y) = \frac{ 6}{ 7} \left(x^2 + \frac{ x y}{ 2}\right), 
    0 < x < 1, 0 < y < 2\]

  \begin{homeworkSection}{Definitions}

  \end{homeworkSection}
  \begin{enumerate}[(a)]
    \item Verify that this is indeed a joint density function.
      \begin{homeworkSection}{Solution}
        \begin{align*}
          \int\limits_0^2 \int\limits_0^1 f( x, y) dx dy &= 
            \int\limits_0^2 \int\limits_0^1 \frac{ 6}{ 7} 
              \left(x^2 + \frac{ x y}{ 2}\right) dx dy\\
          &= \frac{ 6}{ 7} \int\limits_0^2 \int\limits_0^1 
            \left(x^2 + \frac{ x y}{ 2}\right) dx dy\\
          &= \frac{ 6}{ 7} \int\limits_0^2
            \left.\left(\frac{ x^3}{ 3} + \frac{ x^2 y}{ 4}\right)\right|_0^1 dy\\
          &= \frac{ 6}{ 7} \int\limits_0^2
            \left(\frac{ 1}{ 3} + \frac{ y}{ 4}\right) dy\\
          &= \frac{ 6}{ 7}
            \left.\left(\frac{ y}{ 3} + \frac{ y^2}{ 8}\right)\right|_0^2\\
          &= \frac{ 6}{ 7} \left(\frac{ 2}{ 3} + \frac{ 4}{ 8}\right)\\
          &= \frac{ 6}{ 7} \left(\frac{ 7}{ 6}\right)\\
          &= 1\\
        \end{align*}
      \end{homeworkSection}
    \item Compute the density function of $X$.
      \begin{homeworkSection}{Solution}
        \begin{align*}
          f(x) &= \int\limits_0^2 f(x, y) dy\\
          &= \int\limits_0^2 \frac{ 6}{ 7} \left(x^2 + \frac{ x y}{ 2}\right) dy\\
          &= \left.\frac{ 6}{ 7} \left(y x^2 + \frac{ x y^2}{ 4}\right)\right|_0^2\\
          &= \frac{ 6}{ 7} \left(2 x^2 + x \right)\\
        \end{align*}
      \end{homeworkSection}
    \item Find $P\{ X > Y\}$.
      \begin{homeworkSection}{Solution}
        \begin{align*}
          \int\limits_0^1 \int\limits_0^x f( x, y) dy dx
          &= \int\limits_0^1 \int\limits_0^x \frac{ 6}{ 7} \left(x^2 + \frac{ x y}{ 2}\right) dy dx\\
          &= \int\limits_0^1 
            \left.\frac{ 6}{ 7} \left( y x^2 + \frac{ x y^2}{ 4}\right)\right|_0^x dx\\
          &= \int\limits_0^1 \frac{ 6}{ 7} \left( x^3 + \frac{ x^3}{ 4}\right) dx\\
          &= \left.\frac{ 6}{ 7} \left( \frac{ x^4}{ 4} + \frac{ x^4}{ 16}\right)\right|_0^1\\
          &= \frac{ 6}{ 7} \left(\frac{ 5}{ 16}\right)\\
          &= \frac{ 30}{ 112} = \frac{ 15}{ 56}\\
        \end{align*}
      \end{homeworkSection}
    \item Find $P\{ Y > \frac{ 1}{ 2}| X < \frac{ 1}{ 2}\}$.
      \begin{homeworkSection}{Solution}
        \begin{align*}
          \int\limits_\frac{ 1}{ 2}^2 \int\limits_0^\frac{ 1}{ 2} f( x, y) dx dy
          &= \int\limits_\frac{ 1}{ 2}^2 \int\limits_0^\frac{ 1}{ 2} 
            \frac{ 6}{ 7} \left(x^2 + \frac{ x y}{ 2}\right) dx dy\\
          &= \int\limits_\frac{ 1}{ 2}^2 \frac{ 6}{ 7} 
            \left.\left(\frac{ x^3}{ 3} + \frac{ x^2 y}{ 4}\right)\right|_0^\frac{ 1}{ 2} dy\\
          &= \int\limits_\frac{ 1}{ 2}^2 
            \frac{ 6}{ 7} \left(\frac{ 1}{ 24} + \frac{y}{ 16}\right) dy\\
          &= \frac{ 6}{ 7} 
            \left.\left(\frac{ y}{ 24} + \frac{y^2}{ 32}\right)\right|_\frac{ 1}{ 2}^2\\
          &= \frac{ 6}{ 7} 
            \left(\left(\frac{ 1}{ 12} + \frac{1}{ 16}\right) 
            - \left(\frac{ 1}{ 48} + \frac{1}{ 128}\right)\right)\\
          &= \frac{ 6}{ 7} 
            \left(\left(\frac{ 5}{ 32}\right) 
            - \left(\frac{19}{ 384}\right)\right)\\
          &= \frac{ 6}{ 7}\left(\frac{ 41}{ 384}\right)\\
          &= \frac{ 41}{ 448}\\
        \end{align*}
      \end{homeworkSection}
    \item Find $E[ X]$
      \begin{homeworkSection}{Solution}
        \begin{align*}
          E[ X] &= \int\limits_0^2 \int\limits_0^1 x f( x, y) dx dy\\
            &= \int\limits_0^2 \int\limits_0^1 x \frac{ 6}{ 7} 
              \left(x^2 + \frac{ x y}{ 2}\right) dx dy\\
            &= \int\limits_0^2 \int\limits_0^1 \frac{ 6}{ 7} 
              \left(x^3 + \frac{ x^2 y}{ 2}\right) dx dy\\
            &= \int\limits_0^2 \left.\frac{ 6}{ 7} 
              \left(\frac{ x^4}{ 4} + \frac{ x^3 y}{ 6}\right)\right|_0^1 dy\\
            &= \int\limits_0^2 \frac{ 6}{ 7} 
              \left(\frac{ 1}{ 4} + \frac{ y}{ 6}\right) dy\\
            &= \left.\frac{ 6}{ 7} 
              \left(\frac{ y}{ 4} + \frac{ y^2}{ 12}\right)\right|_0^2 \\
            &= \frac{ 6}{ 7} \left(\frac{ 1}{ 2} + \frac{ 1}{ 3}\right) \\
            &= \frac{ 6}{ 7} \left(\frac{ 5}{ 6}\right) \\
            &= \frac{ 5}{ 7} \\
        \end{align*}
      \end{homeworkSection}
    \item Find $E[ Y]$
      \begin{homeworkSection}{Solution}
        \begin{align*}
          E[ X] &= \int\limits_0^2 \int\limits_0^1 y f( x, y) dx dy\\
            &= \int\limits_0^2 \int\limits_0^1 y \frac{ 6}{ 7} 
              \left(x^2 + \frac{ x y}{ 2}\right) dx dy\\
            &= \int\limits_0^2 \int\limits_0^1 \frac{ 6}{ 7} 
              \left( y x^2 + \frac{ x y^2}{ 2}\right) dx dy\\
            &= \int\limits_0^2 \frac{ 6}{ 7} \left.
              \left( \frac{ y x^3}{ 3} + \frac{ x^2 y^2}{ 4}\right)\right|_0^1 dy\\
            &= \int\limits_0^2 \frac{ 6}{ 7}
              \left( \frac{ y}{ 3} + \frac{ y^2}{ 4}\right) dy\\
            &= \frac{ 6}{ 7} \left.
              \left( \frac{ y^2}{ 6} + \frac{ y^3}{ 12}\right)\right|_0^2 \\
            &= \frac{ 6}{ 7} \left( \frac{ 3}{ 4} + \frac{ 2}{ 3}\right)\\
            &= \frac{ 6}{ 7} \left( \frac{ 17}{ 12}\right)\\
            &= \frac{ 17}{ 14}\\
        \end{align*}

      \end{homeworkSection}
  \end{enumerate}
\end{homeworkProblem}

%=============================p.287 #10==========================% 
\newpage
\begin{homeworkProblem}
  {\bf Chapter 6, Exercise 10}\\
  The joint probability density function of $X$ and $Y$ is given by
    \[f( x, y) = e^{-(x + y)}, 0 \le x < \infty, 0 \le y < \infty\]
  Find 
  \begin{enumerate}[(a)]
    \item $P\{ X < Y\}$
      \begin{homeworkSection}{Solution}
        \begin{align*}
          P\{ X < Y\} 
          &= \int\limits_0^\infty \int\limits_0^y f( x, y) dx dy\\
          &= \int\limits_0^\infty \int\limits_0^y e^{-(x + y)} dx dy\\
          &= \int\limits_0^\infty \int\limits_0^y e^{-x} e^{-y} dx dy\\
          &= \int\limits_0^\infty \left. -e^{-x} e^{-y}\right|_0^y dy\\
          &= \int\limits_0^\infty (1 - e^{-y}) e^{-y} dy\\
          &= \int\limits_0^\infty e^{-y} - e^{-2y} dy\\
          &= \left.\frac{ e^{-2y}}{ 2} - e^{-y}\right|_0^\infty\\
          &= \frac{ 1}{ 2}\\
        \end{align*}
      \end{homeworkSection}
    \item $P\{ X < a\}$
      \begin{homeworkSection}{Solution}
        \begin{align*}
          P\{ X < a\} 
          &= \int\limits_0^\infty \int\limits_0^a f( x, y) dx dy\\
          &= \int\limits_0^\infty \int\limits_0^a e^{-(x + y)} dx dy\\
          &= \int\limits_0^\infty \int\limits_0^a e^{-x} e^{-y} dx dy\\
          &= \int\limits_0^\infty \left. -e^{-x} e^{-y}\right|_0^a dy\\
          &= \int\limits_0^\infty (1 - e^{-a}) e^{-y} dy\\
          &= \left. (e^{-a} - 1) e^{-y} \right|_0^\infty\\
          &= (1 - e^{-a})\\
        \end{align*}
      \end{homeworkSection}
  \end{enumerate}
\end{homeworkProblem}

%=============================p.288 #22==========================% 
\newpage
\begin{homeworkProblem}
  {\bf Chapter 6, Exercise 23}\\
  The random variables $X$ and $Y$ have joint density function
  \[f( x, y) = 12 x y (1 - x), 0 < x < 1, 0 < y < 1\]
  and equal to 0 otherwise.
  \begin{enumerate}[(a)]
    \item Are $X$ and $Y$ independent?
      \begin{homeworkSection}{Solution}
          If $X$ and $Y$ are independent then
          \[P\{ X \le a, Y \le b\} = P\{ X \le a \} P\{ Y \le b\}\]

        \begin{align*}
          P\{ X \le a, Y \le b\} &= \int\limits_0^b \int\limits_0^a f( x, y) dx dy\\
          &= \int\limits_0^b \int\limits_0^a 12 x y (1 - x) dx dy\\
          &= \int\limits_0^b \int\limits_0^a 12 x y - 12 x^2 y dx dy\\
          &= \int\limits_0^b \left.6 x^2 y - 4 x^3 y\right|_0^a dy\\
          &= \int\limits_0^b 6 a^2 y - 4 a^3 y dy\\
          &= \left.3 a^2 y^2 - 2 a^3 y^2\right|_0^b\\
          &= 3 a^2 b^2 - 2 a^3 b^2\\
        \end{align*}
        \begin{align*}
          P\{ X \le a\} &= \int\limits_0^1 \int\limits_0^a f( x, y) dx dy\\
          &= \int\limits_0^1 \int\limits_0^a 12 x y (1 - x) dx dy\\
          &= \int\limits_0^1 \int\limits_0^a 12 x y - 12 x^2 y dx dy\\
          &= \int\limits_0^1 \left.6 x^2 y - 4 x^3 y\right|_0^a dy\\
          &= \int\limits_0^1 6 a^2 y - 4 a^3 y dy\\
          &= \left.3 a^2 y^2 - 2 a^3 y^2\right|_0^1\\
          &= 3 a^2 - 2 a^3\\
        \end{align*}
        \begin{align*}
          P\{ Y \le b\} &= \int\limits_0^b \int\limits_0^1 f( x, y) dx dy\\
          &= \int\limits_0^b \int\limits_0^1 12 x y (1 - x) dx dy\\
          &= \int\limits_0^b \int\limits_0^1 12 x y - 12 x^2 y dx dy\\
          &= \int\limits_0^b \left.6 x^2 y - 4 x^3 y\right|_0^1 dy\\
          &= \int\limits_0^b 6 y - 4 y dy\\
          &= \left.3 y^2 - 2 y^2\right|_0^1\\
          &= 3 b^2 - 2 b^2\\
        \end{align*}
        Since
        \[3 a^2 b^2 - 2 a^3 b^2 \neq (3 a^2 - 2 a^3) (3 b^2 - 2 b^2)\]
       $X$ and $Y$ are \emph{not} independent.
      \end{homeworkSection}
    \item Find $E[ X]$
      \begin{homeworkSection}{Solution}
        \begin{align*}
          E[ X] &= \int\limits_0^1 \int\limits_0^1 x f( x, y) dx dy\\
          &= \int\limits_0^1 \int\limits_0^1 x 12 x y (1 - x) dx dy\\
          &= \int\limits_0^1 \int\limits_0^1 12 x^2 y - 12 x^3 y dx dy\\
          &= \int\limits_0^1 \left.4 x^3 y - 3 x^4 y\right|_0^1 dy\\
          &= \int\limits_0^1 4 y  - 3 y dy\\
          &= \left.2 y^2 - \frac{3 y^2}{ 2}\right|_0^1\\
          &= 2 - \frac{3}{ 2}\\
          &= \frac{1}{ 2}\\
        \end{align*}
      \end{homeworkSection}
    \item Find $E[ Y]$
      \begin{homeworkSection}{Solution}
        \begin{align*}
          E[ Y] &= \int\limits_0^1 \int\limits_0^1 y f( x, y) dx dy\\
          &= \int\limits_0^1 \int\limits_0^1 y 12 x y (1 - x) dx dy\\
          &= \int\limits_0^1 \int\limits_0^1 12 x y^2 - 12 x^2 y^2 dx dy\\
          &= \int\limits_0^1 \left.6 x^2 y^2 - 4 x^3 y^2\right|_0^1 dy\\
          &= \int\limits_0^1 6 y^2 - 4 y^2 dy\\
          &= \left. 2 y^3 - \frac{ 4 y^3}{ 3}\right|_0^1\\
          &= 2 - \frac{ 4}{ 3}\\
          &= \frac{ 2}{ 3}\\
        \end{align*}
      \end{homeworkSection}
    \item Find $Var( X)$
      \begin{homeworkSection}{Solution}
        \begin{align*}
          Var( X) &= E[ X^2] - (E[ X])^2\\
          &= \int\limits_0^1 \int\limits_0^1 x^2 f( x, y) dx dy - (\frac{ 1}{ 2})^2\\
          &= \int\limits_0^1 \int\limits_0^1 x^2 12 x y (1 - x) dx dy - \frac{ 1}{ 4}\\
          &= \int\limits_0^1 \int\limits_0^1 12 x^3 y - 12 x^4 y dx dy - \frac{ 1}{ 4}\\
          &= \int\limits_0^1 \left. 3 x^4 y 
            - \frac{ 12 x^5 y}{ 5} \right|_0^1 dy - \frac{ 1}{ 4}\\
          &= \int\limits_0^1  3 y - \frac{ 12 y}{ 5} dy - \frac{ 1}{ 4}\\
          &= \left. \frac{ 3 y^2}{ 2} 
            - \frac{ 6 y^2}{ 5} \right|_0^1 - \frac{ 1}{ 4}\\
          &= \frac{ 3}{ 2} - \frac{ 6}{ 5} - \frac{ 1}{ 4}\\
          &= \frac{ 1}{ 20}\\
        \end{align*}
      \end{homeworkSection}
    \item Find $Var( Y)$
      \begin{homeworkSection}{Solution}
        \begin{align*}
          Var( Y) &= E[ Y^2] - (E[ Y])^2\\
          &= \int\limits_0^1 \int\limits_0^1 y^2 f( x, y) dx dy - (\frac{ 2}{ 3})^2\\
          &= \int\limits_0^1 \int\limits_0^1 y^2 12 x y (1 - x) dx dy - \frac{ 4}{ 9}\\
          &= \int\limits_0^1 \int\limits_0^1 12 x y^3 - 12 x^2 y^3 dx dy - \frac{ 4}{ 9}\\
          &= \int\limits_0^1 \left.6 x^2 y^3 - 4 x^3 y^3 \right|_0^1 dy - \frac{ 4}{ 9}\\
          &= \int\limits_0^1 6 y^3 - 4 y^3 dy - \frac{ 4}{ 9}\\
          &= \int\limits_0^1 \left.6 y^3 - 4 y^3 \right|_0^1 dy - \frac{ 4}{ 9}\\
          &= \left.\frac{ 3y^4}{ 2}  - y^4 \right|_0^1 - \frac{ 4}{ 9}\\
          &= \frac{ 3}{ 2} - 1 - \frac{ 4}{ 9}\\
          &= \frac{ 1}{ 18}\\
        \end{align*}
      \end{homeworkSection}
  \end{enumerate}
\end{homeworkProblem}

%=============================p.289 #28==========================% 
\newpage
\begin{homeworkProblem}
  {\bf Chapter 6, Exercise 28}\\
  The time that it takes to service a car is an exponential 
  random variable with rate 1.
  \begin{homeworkSection}{Definitions}
    {\bf Exponential Random Variable}\\
    A continuous random variable whose probability density 
    function is given, for some $\lambda > 0$, by
      \[
        f(x) = \left\{
          \begin{array}{l l}
            \lambda e^{-\lambda x} &\text{if } x \ge 0\\
            0 &\text{if } x < 0
          \end{array} \right.
      \]
    is said to be an \emph{exponential random variable} (or, more simply, 
    is said to be exponentially distributed) with parameter $\lambda$. 
    The cumulative distribution function $F( a)$ of an exponential 
    random variable is given by
      \begin{align*}
        F(a) &= P\{ X \le a \}\\
        &= \int\limits_0^a \lambda e^{-\lambda x} dx\\
        &= \left.-e^{-\lambda x}\right|_0^a\\
        &= 1 - e^{-\lambda a},  a \ge 0
      \end{align*}
    Where
      \begin{align*}
        E[ X] &= \frac{ 1}{ \lambda}\\
        Var( X) &= \frac{ 1}{ \lambda^2}
      \end{align*}
    \emph{Note}: $F(q) = \int\limits_0^\infty \lambda e^{-\lambda x} dx = 1$, 
    as, of course, it must.
  \end{homeworkSection}
  \begin{enumerate}[(a)]
    \item If A.J. brings his car in at time 0 and M.J.
    brings her car in at time $t$, what is the probability 
    that M. J.'s car is ready before A. J.'s car? 
    (Assume that service times are independent and service 
    begins upon arrival of the car.)
      \begin{homeworkSection}{Solution}
        Since $t \ge 0$ we are dealing the memoryless function of
        of an epoential.
        
        Applying this to the problem, we first find the probabilty that
        A.J.'s car is finished at a time $\le t$.  During this time period, 
        the probability that M.J's care will be serviced is $0$.  Hence
          \begin{align*}
            P\{ \text{A.J.'s gets service} \le t\} &= \lambda \int\limits_0^t e^{-\lambda x} dx\\
            \text{ Letting $\lambda = 1$ to reflect our rate}\\
            &= \left. -e^{-x} \right|_0^t\\
            &= 1 - e^{-t}\\
          \end{align*}

        Now considering the probability that M.J.'s car will be serviced at a time $> t$,
        by the memorylessness of the exponential we find the the probability is $\frac{ 1}{2}$

        Putting everything together, we find that the probability M.J.'s car is serviced before
        A.J's car is
        \begin{align*}
          P\{ \text{ M.J's care is serviced before A.J.'s car} \} 
            &= P\{\text{A.J. waits at least time} t \cap \text{A.J. gets service first after time} t\}\\
            &= P\{\text{A.J. waits at least time} t\} P\{\text{A.J. gets service first after time} t\}\\
            &= \left(\frac{ 1}{ 2}\right) (1 - (1 - e^{-t}))\\
            &= \left(\frac{ 1}{ 2}\right) ( e^{-t})\\
        \end{align*}
      \end{homeworkSection}
    \item If both cars are brought in at time 0, with work 
    starting on M. J.'s car only when A. J.'s car has been 
    completely serviced, what is the probability that M. J.'s 
    car is ready before time 2?
      \begin{homeworkSection}{Solution}
        \begin{align*}
          P\{ \text{ M.J's before time 2}\} 
          &= \int\limits_0^2 \int\limits_y^2 \lambda^2 e^{-\lambda x} e^{-\lambda y} dx dy\\
            \text{ Letting $\lambda = 1$ to reflect our rate}\\
          &= \int\limits_0^2 \int\limits_y^2 e^{-x} e^{-y} dx dy\\
          &= \int\limits_0^2 \left.-e^{-x} e^{-y}\right|_y^2 dy\\
          &= \int\limits_0^2 (e^{-y} - e^{-2}) e^{-y} dy\\
          &= \int\limits_0^2 e^{-2y} - e^{-2} e^{-y} dy\\
          &= \left.\frac{ e^{-2y}}{ -2} + e^{-2} e^{-y}\right|_0^2\\
          &= \left(\frac{ e^{-4}}{ -2} + e^{-2} e^{-2}\right) 
            - \left(\frac{ 1}{ -2} + e^{-2}\right)
        \approx 0.37382253
        \end{align*}
      \end{homeworkSection}
  \end{enumerate}
\end{homeworkProblem}

%=============================p.289 #30==========================% 
\newpage
\begin{homeworkProblem}
  {\bf Chapter 6, Exercise 30}\\
  Jill's bowling scores are approximately normally distributed with 
  mean 170 and standard deviation 20, while Jack's scores are 
  approximately normally distributed with mean 160 and standard 
  deviation 15. If Jack and Jill each bowl one game, then assuming 
  that their scores are independent random variables, approximate 
  the probability that
  \begin{enumerate}[(a)]
    \item Jack's score is higher
      \begin{homeworkSection}{Solution}
        Let $X$ be the random variable of Jack's score and
        $Y$ be the random variable of Jills score.
        \begin{align*}
          X &\sim n( 170, 20^2)\\
          Y &\sim n( 160, 15^2)\\
        \end{align*}
          Since the distrobution of the normal
          is symetric around it's mean
        \begin{align*}
          Y - X &\sim n( 160 - 170, 20^2 + 15^2)\\
          &\sim( -10, 25^2)\\
          \text{Computing the probability}\\
          P\left\{ Y - X \ge \frac{ 1}{ 2}\right\} 
          &= P\left\{ \frac{ (Y - X) - \mu_{Y - X}}{ \sigma_{Y - X}}
            > \frac{ -\frac{ 1}{ 2} - \mu_{Y - X}}{ \sigma_{Y - X}}\right\}\\
          &= P\{ Z > .42 \}\\
          &= 1 - \Phi(.42)\\
          &\simeq .3372\\
        \end{align*}
      \end{homeworkSection}
    \item The total of their scores is above 350
      \begin{homeworkSection}{Solution}
        Let $X$ be the random variable of Jack's score and
        $Y$ be the random variable of Jills score.
        \begin{align*}
          X &\sim n( 170, 20^2)\\
          Y &\sim n( 160, 15^2)\\
        \end{align*}
          Since the distrobution of the normal
          is symetric around it's mean
        \begin{align*}
          Y + X &\sim n( 160 + 170, 20^2 + 15^2)\\
          &\sim( 330, 25^2)\\
          \text{Computing the probability}\\
          P\left\{ Y + X \ge 350.5\right\} 
          &= P\left\{ \frac{ (Y + X) - \mu_{Y + X}}{ \sigma_{Y + X}}
            > \frac{ 350.5 - \mu_{Y + X}}{ \sigma_{Y + X}}\right\}\\
          &= P\{ Z > .82 \}\\
          &= 1 - \Phi(.82)\\
          &\simeq .2061\\
        \end{align*}
      \end{homeworkSection}
  \end{enumerate}
\end{homeworkProblem}

\end{spacing}
\end{document}

\begin{comment}%==========================================================
* p.228
  * 18
  * 19
  * 20
  * 21
  * 26
      * Use p.218(6.3)  and \[\Gamma( n + 1) = n \Gamma( n)\]
* p.287
  * 9
  * 10
  * 23
  * 28
      * exp. significant
  * 30 
      * exp. significant
%=============================Problemi==========================% 
\newpage
\begin{homeworkProblem}
  
  \begin{homeworkSection}{Solution}
    
  \end{homeworkSection}
\end{homeworkProblem}
%=============================Problemi==========================% 
\newpage
\begin{homeworkProblem}
  
  \begin{enumerate}[(a)]
    \item 
      \begin{homeworkSection}{Solution}
    
      \end{homeworkSection}
  \end{enumerate}
\end{homeworkProblem}
